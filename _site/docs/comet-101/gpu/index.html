<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../icon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../icon/favicon-16x16.png"><link rel="manifest" href="../icon/site.webmanifest"><link rel="mask-icon" href="../icon/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="/dev.io/assets/css/just-the-docs-default.css"><link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-blue.min.css" /> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-2709176-10"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-2709176-10', { 'anonymize_ip': true }); </script> <script type="text/javascript" src="/dev.io/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/dev.io/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>comp-and-run-cuda-jobs | SDSC-101-Dev</title><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="comp-and-run-cuda-jobs" /><meta property="og:locale" content="en_US" /><meta name="description" content="SDSC-101 Dev branch" /><meta property="og:description" content="SDSC-101 Dev branch" /><link rel="canonical" href="http://localhost:4000/dev.io/docs/comet-101/gpu/" /><meta property="og:url" content="http://localhost:4000/dev.io/docs/comet-101/gpu/" /><meta property="og:site_name" content="SDSC-101-Dev" /> <script type="application/ld+json"> {"description":"SDSC-101 Dev branch","url":"http://localhost:4000/dev.io/docs/comet-101/gpu/","@type":"WebPage","headline":"comp-and-run-cuda-jobs","@context":"https://schema.org"}</script> <button class="btn js-toggle-dark-mode">dark scheme</button> <script> const toggleDarkMode = document.querySelector('.js-toggle-dark-mode'); jtd.addEvent(toggleDarkMode, 'click', function(){ if (jtd.getTheme() === 'dark') { jtd.setTheme('light'); toggleDarkMode.textContent = 'dark scheme'; } else { jtd.setTheme('dark'); toggleDarkMode.textContent = 'light scheme'; } }); </script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="http://localhost:4000/dev.io/" class="site-title lh-tight"> SDSC-101-Dev </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/dev.io/docs/comet" class="nav-list-link">Comet 101</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/comet-101/Comet%20Overview/" class="nav-list-link">Comet Overview</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/comet-101/Getting%20Started%20on%20Comet/" class="nav-list-link">Getting Started on Comet</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/comet-101/Customizing/" class="nav-list-link">Customizing Your User Environment</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/comet-101/Compiling/" class="nav-list-link">Compiling & Linking</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/comet-101/Running%20Jobs/" class="nav-list-link">Running Jobs on Comet</a><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/dev.io/docs/comet/examples" class="nav-list-link">Hands-on Examples</a><ul class="nav-list"><li class="nav-list-item active"> <a href="http://localhost:4000/dev.io/docs/comet-101/gpu/" class="nav-list-link active">comp-and-run-cuda-jobs</a><li class="nav-list-item "> <a href="http://localhost:4000/dev.io/docs/comet-101/cpu/" class="nav-list-link">Compiling and Running CPU Jobss</a></ul></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/dev.io/docs/expanse" class="nav-list-link">Expanse 101</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/expanse-101/Expanse%20Overview/" class="nav-list-link">Expanse Overview</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/expanse-101/start/" class="nav-list-link">Getting Started on Expanse</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/expanse-101/Customizing/" class="nav-list-link">Customizing Your User Environment</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/expanse-101/Compiling/" class="nav-list-link">Compiling & Linking</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/expanse-101/slurm/" class="nav-list-link">Using Slurm on Comet</a><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/dev.io/docs/expanse/examples" class="nav-list-link">Hands-on Examples</a><ul class="nav-list"><li class="nav-list-item "> <a href="http://localhost:4000/dev.io/docs/expanse-101/gpu/" class="nav-list-link">comp-and-run-cuda-jobs</a><li class="nav-list-item "> <a href="http://localhost:4000/dev.io/docs/expanse-101/cpu/" class="nav-list-link">Compiling and Running CPU Jobs</a></ul></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/dev.io/docs/notebooks" class="nav-list-link">notebooks-101</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/notebooks-101/contactus/" class="nav-list-link">Contact Us</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/notebooks-101/overview/" class="nav-list-link">Jupyter Notebook Overview</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/notebooks-101/prerequisites/" class="nav-list-link">Software Prerequisites</a><li class="nav-list-item "><a href="http://localhost:4000/dev.io/docs/notebooks-101/aboutus/" class="nav-list-link">About the Team</a><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/dev.io/docs/notebooks/examples" class="nav-list-link">Example Notebooks</a><ul class="nav-list"><li class="nav-list-item "> <a href="http://localhost:4000/dev.io/docs/notebooks-101/httpConnect/" class="nav-list-link">Insecurity with direct node access</a><li class="nav-list-item "> <a href="http://localhost:4000/dev.io/docs/notebooks-101/reverseProxy/" class="nav-list-link">Security with Reverse Proxy Service</a><li class="nav-list-item "> <a href="http://localhost:4000/dev.io/docs/notebooks-101/runJupyterMethods/" class="nav-list-link">Jupyter Services on Comet</a><li class="nav-list-item "> <a href="http://localhost:4000/dev.io/docs/notebooks-101/tunneling/" class="nav-list-link">Security with SSH Tunneling</a></ul></ul></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search SDSC-101-Dev" aria-label="Search SDSC-101-Dev" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="" class="site-button" > SDSC 101 on GitHub </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/dev.io/docs/comet">Comet 101</a><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/dev.io/docs/expanse/examples">Hands-on Examples</a><li class="breadcrumb-nav-list-item"><span>comp-and-run-cuda-jobs</span></ol></nav><div id="main-content" class="main-content" role="main"><h2 id="compiling-and-running-gpucuda-jobs"> <a href="#compiling-and-running-gpucuda-jobs" class="anchor-heading" aria-labelledby="compiling-and-running-gpucuda-jobs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a name="comp-and-run-cuda-jobs"></a>Compiling and Running GPU/CUDA Jobs</h2><p><b>Sections:</b></p><ul><li><a href="#hello-world-gpu">GPU Hello World (GPU) </a><li><a href="#enum-gpu">GPU Enumeration </a><li><a href="#mat-mul-gpu">CUDA Mat-Mult</a></ul><p>Note: Comet provides both NVIDIA K80 and P100 GPU-based resources. These GPU nodes are allocated as separate resources. Make sure you have enough allocations and that you are using the right account. For more details and current information about the Comet GPU nodes, see the <a href="https://www.sdsc.edu/support/user_guides/comet.html#gpu">Comet User Guide</a>.</p><p><b> Comet GPU Hardware: </b> <br /> <a name="gpu-hardware"></a><img src="images/comet-gpu-hardware.png" alt="Comet GPU Hardware" width="500px" /></p><h2 id="in-order-to-compile-the-cuda-code-you-need-to-load-the-cuda-module-and-verify"> <a href="#in-order-to-compile-the-cuda-code-you-need-to-load-the-cuda-module-and-verify" class="anchor-heading" aria-labelledby="in-order-to-compile-the-cuda-code-you-need-to-load-the-cuda-module-and-verify"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> In order to compile the CUDA code, you need to load the CUDA module and verify</h2><p>that you have access to the CUDA compile command, <code class="language-plaintext highlighter-rouge">nvcc:</code></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[mthomas@comet-ln3:~/comet101] module list
Currently Loaded Modulefiles:
1) intel/2018.1.163    2) mvapich2_ib/2.3.2
[mthomas@comet-ln3:~/comet101] module purge
[mthomas@comet-ln3:~/comet101] module load cuda
[mthomas@comet-ln3:~/comet101] module list
Currently Loaded Modulefiles:
1) cuda/10.1
[mthomas@comet-ln3:~/comet101] which nvcc
/usr/local/cuda-10.1/bin/nvcc
</code></pre></div></div><p><a href="#comp-and-run-cuda-jobs">Back to GPU/CUDA Jobs</a> <br /> <a href="#top">Back to Top</a></p><hr /><h3 id="gpucuda-example-hello-world"> <a href="#gpucuda-example-hello-world" class="anchor-heading" aria-labelledby="gpucuda-example-hello-world"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a name="hello-world-gpu"></a>GPU/CUDA Example: Hello World</h3><p><b>Subsections:</b></p><ul><li><a href="#hello-world-gpu-compile">GPU Hello World: Compiling</a><li><a href="#hello-world-gpu-batch-submit">GPU Hello World: Batch Script Submission</a><li><a href="#hello-world-gpu-batch-output">GPU Hello World: Batch Job Output</a></ul><h4 id="gpu-hello-world-compiling"> <a href="#gpu-hello-world-compiling" class="anchor-heading" aria-labelledby="gpu-hello-world-compiling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a name="hello-world-gpu-compile"></a>GPU Hello World: Compiling</h4><p>Simple hello runs a cuda command to get the device count on the node that job is assigned to. :</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[mthomas@comet-ln3:~/comet101] cd CUDA/hello_cuda
[mthomas@comet-ln3:~/comet101/CUDA/hello_cuda] ll
total 30
drwxr-xr-x 2 mthomas use300   4 Apr 16 01:59 .
drwxr-xr-x 4 mthomas use300  11 Apr 16 01:57 ..
-rw-r--r-- 1 mthomas use300 313 Apr 16 01:59 hello_cuda.cu
-rw-r--r-- 1 mthomas use300 269 Apr 16 01:58 hello_cuda.sb
[mthomas@comet-ln3:~/comet101/CUDA/cuda_hello]  cat hello_cuda.cu
/*
* hello_cuda.cu
* Copyright 1993-2010 NVIDIA Corporation.
*    All right reserved
*/
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
int main( void )
{
int deviceCount;
cudaGetDeviceCount( &amp;deviceCount );
printf("Hello, Webinar Participants! You have %d devices\n", deviceCount );
return 0;
}
</code></pre></div></div><ul><li>Compile using the <code class="language-plaintext highlighter-rouge">nvcc</code>&lt;/b&gt; command: ``` [mthomas@comet-ln3:~/comet101/CUDA/cuda_hello] nvcc -o hello_cuda hello_cuda.cu [mthomas@comet-ln3:~/comet101/CUDA/cuda_hello] ll hello_cuda -rwxr-xr-x 1 user use300 517437 Apr 10 19:35 hello_cuda -rw-r–r– 1 user use300 304 Apr 10 19:35 hello_cuda.cu [comet-ln2:~/cuda/hello_cuda]</ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

#### &lt;a name="hello-world-gpu-batch-submit"&gt;&lt;/a&gt;GPU Hello World: Batch Script Submit

* GPU jobs can be run via the slurm scheduler, or on interactive nodes.
* The slurm scheduler batch script is shown below:
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/cuda_hello] cat hello_cuda.sb #!/bin/bash #SBATCH –job-name=”hello_cuda” #SBATCH –output=”hello_cuda.%j.%N.out” #SBATCH –partition=gpu-shared #SBATCH –nodes=1 #SBATCH –ntasks-per-node=12 #SBATCH –gres=gpu:2 #SBATCH -t 01:00:00</p><h1 id="define-the-user-environment"> <a href="#define-the-user-environment" class="anchor-heading" aria-labelledby="define-the-user-environment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Define the user environment</h1><p>source /etc/profile.d/modules.sh module purge module load intel module load mvapich2_ib #Load the cuda module module load cuda</p><p>#Run the job ./hello_cuda</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Some of the batch script variables are described below. For more details see
the Comet user guide.
* GPU nodes can be accessed via either the "gpu" or the "gpu-shared" partitions:
</code></pre></div></div><p>#SBATCH -p gpu</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>or
</code></pre></div></div><p>#SBATCH -p gpu-shared</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In addition to the partition name (required), the type of gpu (optional) and 
the individual GPUs are scheduled as a resource.
</code></pre></div></div><p>#SBATCH –gres=gpu[:type]:n</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
GPUs will be allocated on a first available, first schedule basis, unless specified with the [type] option, where type can be &lt;b&gt;`k80`&lt;/b&gt; or &lt;b&gt;`p100`&lt;/b&gt; Note: type is case sensitive.
</code></pre></div></div><p>#SBATCH –gres=gpu:4 #first available gpu node #SBATCH –gres=gpu:k80:4 #only k80 nodes #SBATCH –gres=gpu:p100:4 #only p100 nodes</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;b&gt;Submit the job&lt;/b&gt; &lt;br&gt;

To run the job, type the batch script submission command:
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/cuda_hello] sbatch hello_cuda.sb Submitted batch job 32663172 [mthomas@comet-ln3:~/comet101/CUDA/cuda_hello]</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;b&gt;Monitor the job until it is finished:&lt;/b&gt;
</code></pre></div></div><p>[user@comet-ln2:~/cuda/hello_cuda] squeue -u mthomas [mthomas@comet-ln3:~/comet101/CUDA/cuda_hello] sbatch hello_cuda.sb Submitted batch job 32663081 [mthomas@comet-ln3:~/comet101/CUDA/cuda_hello] squeue -u mthomas JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32663081 gpu-share hello_cu mthomas PD 0:00 1 (Resources)</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

#### &lt;a name="hello-world-gpu-batch-output"&gt;&lt;/a&gt;GPU Hello World: Batch Job Output
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/cuda_hello] cat hello_cuda.32663172.comet-30-04.out</p><p>Hello, Webinar Participants! You have 2 devices</p><p>[mthomas@comet-ln3:~/comet101/CUDA/cuda_hello]</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;


### &lt;a name="enum-gpu"&gt;&lt;/a&gt;GPU/CUDA Example: Enumeration

Sections:
* [GPU Enumeration: Compiling](#enum-gpu-compile)
* [GPU Enumeration: Batch Script Submission](#enum-gpu-batch-submit)
* [GPU Enumeration: Batch Job Output](#enum-gpu-batch-output )

&lt;hr&gt;

#### &lt;a name="enum-gpu-compile"&gt;&lt;/a&gt;GPU Enumeration: Compiling

&lt;b&gt;GPU Enumeration Code:&lt;/b&gt;
This code accesses the cudaDeviceProp object and returns information about the devices on the node. The list below is only some of the information that you can look for. The property values can be used to dynamically allocate or distribute your compute threads accross the GPU hardware in response to the GPU type.
</code></pre></div></div><p>[user@comet-ln2:~/cuda/gpu_enum] cat gpu_enum.cu #include <stdio.h></stdio.h></p><p>int main( void ) { cudaDeviceProp prop; int count; printf( “ — Obtaining General Information for CUDA devices —\n” ); cudaGetDeviceCount( &amp;count ) ; for (int i=0; i&lt; count; i++) { cudaGetDeviceProperties( &amp;prop, i ) ; printf( “ — General Information for device %d —\n”, i ); printf( “Name: %s\n”, prop.name );</p><p>printf( “Compute capability: %d.%d\n”, prop.major, prop.minor ); printf( “Clock rate: %d\n”, prop.clockRate ); printf( “Device copy overlap: “ );</p><p>if (prop.deviceOverlap) printf( “Enabled\n” ); else printf( “Disabled\n”);</p><p>printf( “Kernel execution timeout : “ );</p><p>if (prop.kernelExecTimeoutEnabled) printf( “Enabled\n” ); else printf( “Disabled\n” );</p><p>printf( “ — Memory Information for device %d —\n”, i ); printf( “Total global mem: %ld\n”, prop.totalGlobalMem ); printf( “Total constant Mem: %ld\n”, prop.totalConstMem ); printf( “Max mem pitch: %ld\n”, prop.memPitch ); printf( “Texture Alignment: %ld\n”, prop.textureAlignment ); printf( “ — MP Information for device %d —\n”, i ); printf( “Multiprocessor count: %d\n”, prop.multiProcessorCount ); printf( “Shared mem per mp: %ld\n”, prop.sharedMemPerBlock ); printf( “Registers per mp: %d\n”, prop.regsPerBlock ); printf( “Threads in warp: %d\n”, prop.warpSize ); printf( “Max threads per block: %d\n”, prop.maxThreadsPerBlock ); printf( “Max thread dimensions: (%d, %d, %d)\n”, prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2] ); printf( “Max grid dimensions: (%d, %d, %d)\n”, prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2] ); printf( “\n” ); } }</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
To compile: check your environment and use the CUDA &lt;b&gt;`nvcc`&lt;/b&gt; command:
</code></pre></div></div><p>[comet-ln2:~/cuda/gpu_enum] module purge [comet-ln2:~/cuda/gpu_enum] which nvcc /usr/bin/which: no nvcc in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/sdsc/bin:/opt/sdsc/sbin:/opt/ibutils/bin:/usr/java/latest/bin:/opt/pdsh/bin:/opt/rocks/bin:/opt/rocks/sbin:/home/user/bin) [comet-ln2:~/cuda/gpu_enum] module load cuda [comet-ln2:~/cuda/gpu_enum] which nvcc /usr/local/cuda-7.0/bin/nvcc [comet-ln2:~/cuda/gpu_enum] nvcc -o gpu_enum -I. gpu_enum.cu [comet-ln2:~/cuda/gpu_enum] ll gpu_enum -rwxr-xr-x 1 user use300 517632 Apr 10 18:39 gpu_enum [comet-ln2:~/cuda/gpu_enum]</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

#### &lt;a name="enum-gpu-batch-submit"&gt;&lt;/a&gt;GPU Enumeration: Batch Script Submission
&lt;b&gt;Contents of the Slurm script &lt;/b&gt;
Script is asking for 1 GPU.

</code></pre></div></div><p>[comet-ln2: ~/cuda/gpu_enum] cat gpu_enum.sb #!/bin/bash #SBATCH –job-name=”gpu_enum” #SBATCH –output=”gpu_enum.%j.%N.out” #SBATCH –partition=gpu-shared # define GPU partition #SBATCH –nodes=1 #SBATCH –ntasks-per-node=6 #SBATCH –gres=gpu:1 # define type of GPU #SBATCH -t 00:05:00</p><h1 id="define-the-user-environment-1"> <a href="#define-the-user-environment-1" class="anchor-heading" aria-labelledby="define-the-user-environment-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Define the user environment</h1><p>source /etc/profile.d/modules.sh module purge module load intel module load mvapich2_ib #Load the cuda module module load cuda</p><p>#Run the job ./gpu_enum</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;b&gt;Submit the job &lt;/b&gt;
* To run the job, type the batch script submission command:
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/gpu_enum] sbatch hello_cuda.sb Submitted batch job 32663364</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;b&gt;Monitor the job &lt;/b&gt;
* You can monitor the job until it is finished using the `sqeue` command:
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/gpu_enum] squeue -u mthomas JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32663364 gpu-share gpu_enum mthomas PD 0:00 1 (Resources)</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

#### &lt;a name="enum-gpu-batch-output"&gt;&lt;/a&gt;GPU Enumeration: Batch Job Output

* Output from script is for multiple devices, which is what was specified in script.

</code></pre></div></div><p>[user@comet-ln2:~/cuda/gpu_enum] cat gpu_enum.22527745.comet-31-10.out — Obtaining General Information for CUDA devices — — General Information for device 0 — — Obtaining General Information for CUDA devices — — General Information for device 0 — Name: Tesla P100-PCIE-16GB Compute capability: 6.0 Clock rate: 1328500 Device copy overlap: Enabled Kernel execution timeout : Disabled — Memory Information for device 0 — Total global mem: 17071734784 Total constant Mem: 65536 Max mem pitch: 2147483647 Texture Alignment: 512 — MP Information for device 0 — Multiprocessor count: 56 Shared mem per mp: 49152 Registers per mp: 65536 Threads in warp: 32 Max threads per block: 1024 Max thread dimensions: (1024, 1024, 64) Max grid dimensions: (2147483647, 65535, 65535)</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* If we change the batch script to ask for 2 devices (see line 8):
</code></pre></div></div><p>1 #!/bin/bash 2 #SBATCH –job-name=”gpu_enum” 3 #SBATCH –output=”gpu_enum.%j.%N.out” 4 #SBATCH –partition=gpu-shared # define GPU partition 5 #SBATCH –nodes=1 6 #SBATCH –ntasks-per-node=6 7 ####SBATCH –gres=gpu:1 # define type of GPU 8 #SBATCH –gres=gpu:2 # first available 9 #SBATCH -t 00:05:00 10 11 # Define the user environment 12 source /etc/profile.d/modules.sh 13 module purge 14 module load intel 15 module load mvapich2_ib 16 #Load the cuda module 17 module load cuda 18 19 #Run the job 20 ./gpu_enum</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
The output will show information for two devices:
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/gpu_enum] sbatch gpu_enum.sb !Submitted batch job 32663404 [mthomas@comet-ln3:~/comet101/CUDA/gpu_enum] squeue -u mthomas JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32663404 gpu-share gpu_enum mthomas CG 0:02 1 comet-33-03 [mthomas@comet-ln3:~/comet101/CUDA/gpu_enum] cat gpu_enumX.32663404.comet-33-03.out — Obtaining General Information for CUDA devices — — General Information for device 0 — Name: Tesla P100-PCIE-16GB Compute capability: 6.0 Clock rate: 1328500 Device copy overlap: Enabled Kernel execution timeout : Disabled — Memory Information for device 0 — Total global mem: 17071734784 Total constant Mem: 65536 Max mem pitch: 2147483647 Texture Alignment: 512 — MP Information for device 0 — Multiprocessor count: 56 Shared mem per mp: 49152 Registers per mp: 65536 Threads in warp: 32 Max threads per block: 1024 Max thread dimensions: (1024, 1024, 64) Max grid dimensions: (2147483647, 65535, 65535)</p><p>— General Information for device 1 — Name: Tesla P100-PCIE-16GB Compute capability: 6.0 Clock rate: 1328500 Device copy overlap: Enabled Kernel execution timeout : Disabled — Memory Information for device 1 — Total global mem: 17071734784 Total constant Mem: 65536 Max mem pitch: 2147483647 Texture Alignment: 512 — MP Information for device 1 — Multiprocessor count: 56 Shared mem per mp: 49152 Registers per mp: 65536 Threads in warp: 32 Max threads per block: 1024 Max thread dimensions: (1024, 1024, 64) Max grid dimensions: (2147483647, 65535, 65535)</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

### &lt;a name="mat-mul-gpu"&gt;&lt;/a&gt;GPU/CUDA Example: Matrix-Multiplication
&lt;b&gt;Subsections:&lt;/b&gt;
* [Matrix Mult. (GPU): Compiling](#mat-mul-gpu-compile)
* [Matrix Mult. (GPU): Batch Script Submission](#mat-mul-gpu-batch-submit)
* [Matrix Mult. (GPU): Batch Job Output](#mat-mul-gpu-batch-output )

#### &lt;a name="mat-mul-gpu"&gt;&lt;/a&gt;CUDA Example: Matrix-Multiplication
&lt;b&gt;Change to the CUDA Matrix-Multiplication example directory:&lt;/b&gt;
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/matmul] ll total 454 drwxr-xr-x 2 mthomas use300 11 Apr 16 02:59 . drwxr-xr-x 5 mthomas use300 5 Apr 16 02:37 .. -rw-r–r– 1 mthomas use300 253 Apr 16 01:56 cuda_matmul.sb -rw-r–r– 1 mthomas use300 5106 Apr 16 01:46 exception.h -rw-r–r– 1 mthomas use300 1168 Apr 16 01:46 helper_functions.h -rw-r–r– 1 mthomas use300 29011 Apr 16 01:46 helper_image.h -rw-r–r– 1 mthomas use300 23960 Apr 16 01:46 helper_string.h -rw-r–r– 1 mthomas use300 15414 Apr 16 01:46 helper_timer.h -rwxr-xr-x 1 mthomas use300 652768 Apr 16 01:46 matmul -rw-r–r– 1 mthomas use300 13482 Apr 16 02:36 matmul.cu -rw-r–r– 1 mthomas use300 370 Apr 16 02:59 matmul.sb</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

#### &lt;a name="mat-mul-gpu-compile"&gt;&lt;/a&gt;Compiling CUDA Example (GPU)

&lt;b&gt; Compile the code:&lt;/b&gt;
</code></pre></div></div><p>[user@comet-ln2 CUDA]$ nvcc -o matmul -I. matrixMul.cu [user@comet-ln2 CUDA]$ ll total 172 drwxr-xr-x 2 user user300 13 Aug 6 00:53 . drwxr-xr-x 16 user user300 16 Aug 5 19:02 .. -rw-r–r– 1 user user300 458 Aug 6 00:35 CUDA.18347152.comet-33-02.out -rw-r–r– 1 user user300 458 Aug 6 00:37 CUDA.18347157.comet-33-02.out -rw-r–r– 1 user user300 446 Aug 5 19:02 CUDA.8718375.comet-30-08.out -rw-r–r– 1 user user300 253 Aug 5 19:02 cuda.sb -rw-r–r– 1 user user300 5106 Aug 5 19:02 exception.h -rw-r–r– 1 user user300 1168 Aug 5 19:02 helper_functions.h -rw-r–r– 1 user user300 29011 Aug 5 19:02 helper_image.h -rw-r–r– 1 user user300 23960 Aug 5 19:02 helper_string.h -rw-r–r– 1 user user300 15414 Aug 5 19:02 helper_timer.h -rwxr-xr-x 1 user user300 533168 Aug 6 00:53 matmul -rw-r–r– 1 user user300 13482 Aug 6 00:50 matrixMul.cu</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

#### &lt;a name="mat-mul-gpu-batch-submit"&gt;&lt;/a&gt;Matrix Mult. (GPU): Batch Script Submission

&lt;b&gt;Contents of the slurm script:&lt;/b&gt;
</code></pre></div></div><p>[user@comet-ln2 CUDA]$ cat cuda.sb #!/bin/bash #SBATCH –job-name=”matmul” #SBATCH –output=”matmul.%j.%N.out” #SBATCH –partition=gpu-shared #SBATCH –nodes=1 #SBATCH –ntasks-per-node=6 #SBATCH –gres=gpu:1 #SBATCH -t 00:10:00</p><h1 id="define-the-user-environment-2"> <a href="#define-the-user-environment-2" class="anchor-heading" aria-labelledby="define-the-user-environment-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Define the user environment</h1><p>source /etc/profile.d/modules.sh module purge module load intel module load mvapich2_ib #Load the cuda module module load cuda</p><p>#Run the job ./matmul</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;b&gt; Submit the job:&lt;/b&gt;
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/matmul] sbatch matmul.sb Submitted batch job 32663647</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;b&gt;Monitor the job:&lt;/b&gt;
</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/matmul] squeue -u mthomas JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 32663647 gpu-share matmul mthomas PD 0:00 1 (Resources) [mthomas@comet-ln3:~/comet101/CUDA/matmul]</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Back to GPU/CUDA Jobs](#comp-and-run-cuda-jobs) &lt;br&gt;
[Back to Top](#top)
&lt;hr&gt;

#### &lt;a name="mat-mul-gpu-batch-output"&gt;&lt;/a&gt;Matrix Mult. (GPU): Batch Job Output

</code></pre></div></div><p>[mthomas@comet-ln3:~/comet101/CUDA/matmul] cat matmul.32663647.comet-33-03.out [Matrix Multiply Using CUDA] - Starting… GPU Device 0: “Tesla P100-PCIE-16GB” with compute capability 6.0</p><p>MatrixA(320,320), MatrixB(640,320) Computing result using CUDA Kernel… done Performance= 1676.99 GFlop/s, Time= 0.078 msec, Size= 131072000 Ops, WorkgroupSize= 1024 threads/block Checking computed result for correctness: Result = PASS</p><p>NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled. ```</p><p><a href="#comp-and-run-cuda-jobs">Back to GPU/CUDA Jobs</a> <br /> <a href="#top">Back to Top</a></p><hr /><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><p class="text-small text-grey-dk-000 mb-0">Copyright &copy; Cyber Infrastructure Machine Learning MIT license.</a></p><div class="d-flex mt-2"><p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/Lzy17/expanse101-Jekyll/tree/main/docs/comet-101/gpu.md" id="edit-this-page">Edit this page on GitHub</a></p></div></footer></div></div><div class="search-overlay"></div></div>
